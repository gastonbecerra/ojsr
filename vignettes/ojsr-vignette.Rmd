---
title: "ojsr-vignette"
author: "Gaston Becerra"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ojsr-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include = FALSE}
library(knitr)
```


# PENDIENTES, ANTES DE CRAN

```{r eval=FALSE, include=FALSE}
library(ojsr)
ojsr::get_issue_url(input_url = "http://revistas.innovacionumh.es/index.php?journal=rpsa&page=index") # genera error y muere
# hay que cerrar conexiones

```





# Overview

The aim of this package is to aid you in several OJS tasks, such as: 

- parse OJS urls, according to routing conventions;
- crawling archives, issues, articles, galleys;
- retrieving/scraping meta-data from articles.

## Important! 

- Most of ojsr functions rely on **OJS routing/links conventions and default themes** (see "process_urls()" below), and therefore are most likely to fail when used on customized OJS installments (i.e., customized themes, routing improvements via .htaccess), and on OJS configuration with poor record keeping.
- Only **OJS v1+ and v2+** have been considered (see "OJS v3 and OJS API" below).

## About OJS

(from the OJS documentation <https://pkp.sfu.ca/ojs/>, as of Jan.2020)

Open Journal Systems (OJS) is a journal management and publishing system that has been developed by the Public Knowledge Project through its federally funded efforts to expand and improve access to research.

OJS assists with every stage of the refereed publishing process, from submissions through to online publication and indexing. Through its management systems, its finely grained indexing of research, and the context it provides for research, OJS seeks to improve both the scholarly and public quality of refereed research.

OJS is open source software made freely available to journals worldwide for the purpose of making open access publishing a viable option for more journals, as open access can increase a journal’s readership as well as its contribution to the public good on a global scale (see PKP Publications).

## OJS v3 and OJS API

Since OJS v3.1+ <https://docs.pkp.sfu.ca/dev/api/ojs/3.1> a Rest API is provided. We're positive a better R interface should use that API instead of scraping web themes and/or OAI records. 

So, why ojsr? According to <https://pkp.sfu.ca/ojs/ojs-usage/ojs-stats/>, as of 2019 (when v3.1+ was launched), OJS was being used by at least 10,000 journals worldwide. OJS is an excellent free publishing solution for institutions that could not publish otherwise. Presumably, most of them do not have the the technical nor financial capabilities to update constantly, so OJS v1+ and v2+ are expected to be around for some time... 



# Installation

```{r message=FALSE, warning=FALSE}
# let's start by loading the libraries
library(ojsr) 
library(tidyverse) # we'll use dplyr and tidy several times in the examples
```



# How to use ojsr?

## process_urls: Parse urls to check what type of OJS page they point at

`process_urls()` allows you to parse a list of urls against OJS routing conventions to extract the parameters invoked (e.g., article, issues, galley IDs) and generate the *conventional* url for specific purposes, such as scraping meta-data from articles, or scraping the list of issues from the archive page. `process_urls()` is invoked from `get_*_url*` functions before scraping when `use_contentional_url = TRUE` (default). 

**Important:** `process_urls()` works with **routing conventions** (see <https://docs.pkp.sfu.ca/dev/documentation/en/architecture-routes>). The list of urls you input is not actually browsed!

If you are planning to summarize information by journal, you may also use `process_urls()` to join links scraped with `get_*_url*` functions, by the `$base_url` of the journal.


```{r message=FALSE, warning=FALSE}
# urls pointing at different types of OJS pages
url_sample <- c( 'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/2903',  # article view
          'http://fundacionmenteclara.org.ar/revista/index.php/RCA/issue/view/2018-Vol3-2', # issue (with ToC)
          'http://fundacionmenteclara.org.ar/revista/index.php/RCA/article/download/43/54', # pdf download
          'https://firstmonday.org/ojs/index.php/fm/article/view/9540', # article view
          'http://imed.pub/ojs/index.php/iam/article/view/1650', # article view
          'http://fundacionmenteclara.org.ar/revista/index.php/RCA/oai', # oai protocol
          'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/view/444', # issue (no ToC)
          'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/search/search?query=complejidad' # search result
)

# we'll parse them, and store the result in a dataframes (`what_type_of_urls`)
what_type_of_urls <- ojsr::process_urls(url_sample)
```

The resulting dataframe contains the following columns:

1. *input_url* - the url you provided
2. *base_url* - base url of the OJS
3. *issue_id* - if an issue, its ID (string); otherwise NA
4. *article_id* - if an article, its ID (string); otherwise NA
5. *galley_id* - if a galley (full-content, supplementary materials, etc.), its ID (string); otherwise NA
6. *conventional_archive* - the *conventional* form of the url you should use to scrap the list of issues
7. *conventional_issue* - the *conventional* form of the url you should use to scrap the ToC from an issue (if issueID is present, otherwise "")
8. *conventional_article* - the *conventional* form of the url you should use to scrap metadata from an article (if articleID is present, otherwise "")
9. *conventional_oai* - the *conventional* form of the url you should use to access OAI
10. *conventional_search* - the *conventional* form of the url you should use to scrap search results



## get_issue_url: Scraps issues urls from OJS pages

`get_issue_url()` takes a vector of OJS urls and scraps them to retrieve the links to OJS issues. Search criteria: links containing "/issue/view" (`method='scrap_by_href_convention'`, default).

If you'd like to retrieve the url of all the issues from a journal, the ideal page to scrap is the archive (e.g., <https://papiro.unizar.es/ojs/index.php/rc51-jos/issue/archive>). If you don't know the url for the archive page, you may provide any url for the journal, and keep `use_conventional_url = TRUE` (default): ojsr will parse the urls given with `process_urls()` to form the conventional url (`$conventional_archive`) for the archive page.

```{r}
socPsy_urls <- c( # argentinian social psychology journals
  'https://dspace.palermo.edu/ojs/index.php/psicodebate/issue/archive', # points at the archive of issues
  'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/2903' # points at an article; ojsr will use process_url() to form the right link to scrap
)
issues <- ojsr::get_issue_url(socPsy_urls, use_conventional_url = TRUE, verbose = TRUE)
```

Result is in a long-format dataframe (1 input_url may result in several rows, one for each output_url), containing:

1. *input_url* - the url you provided
2. *output_url* - the articles url scraped



## get_article_url: Scrap articles urls from OJS pages

`get_article_url()` takes a vector of OJS urls and scraps them to retrieve the links to articles. There are 2 possible search criteria: 

- links containing the "/article/view" convention, and then filtering only those with no "pdf" or "file" classes (usually pointing to a galley, such as, full-content, secondary reading formats, and/or supplementary files) (`method='scrap_by_href_convention_no_classes'`, default).
- links containing the "/article/view" convention, without further filtering (`method='scrap_by_href_convention'`). If the page you are scraping contains links both to articles and their galleys, these may result in more than one link to an article.

If you'd like to retrieve the url of all the articles from an issue, the ideal place to scrap is the issue ToC (e.g., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/view/319/showToc>). Issue pages in OJS may or may not show a cover page, and show or not show the table of contents with links to articles. Usually, you can force the display of the ToC by adding "/ShowToC" to the url. This is all taken care of if you keep `use_conventional_url = TRUE` (default): ojsr will parse the urls given with `process_urls()` to form the conventional url (`$conventional_issue`) for the issue page.

```{r}
socPsy_issues_url <- c( #  initial issues from a few social psychology journals
  'https://revistas.ucn.cl/index.php/saludysociedad/issue/view/65', # includes ToC
  'https://dspace.palermo.edu/ojs/index.php/psicodebate/issue/view/Psicodebate%201', # includes ToC
  'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/view/31' # does not include ToC, nor links to articles
)
articles <- ojsr::get_article_url(socPsy_issues_url, use_conventional_url = TRUE, verbose = TRUE) 
```

Result is in a long-format dataframe (1 input_url may result in several rows, one for each output_url), containing:

1. *input_url* - the url you provided
2. *output_url* - the articles url scraped



## get_galley_url: Scrap galleys urls from OJS pages

*Galleys* are the final presentation version of the content of the articles. Most of the time, these include the full-content in pdf and other reading formats. Less often, they are supplementary files (tables, dataset) in different formats. 

`get_galley_url()` takes a vector of OJS urls and scraps them to retrieve the links to galleys. Search criteria: links containing classes "file", "download" or "obj_galley_link" (`method='scrap_by_class_convention'`, default).

Galleys are linked from several pages in OJS. However, the safest place to search for them is in the view of articles (e.g., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/593>). If you provide an url with an article ID (it could be a view of the article, another galley, etc.), and keep `use_conventional_url = TRUE` (default), ojsr will parse the urls given with `process_urls()` to form the conventional url (`$conventional_article`) for the article view page.

```{r}
socPsy_articles <- c( # 3 articles on social psychology, specifically social representations theory
  'https://revistapsicologia.uchile.cl/index.php/RDP/article/view/55657', # 2 galleys: pdf and mp3
  'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/2137', # 1 galley: pdf
  'https://dspace.palermo.edu/ojs/index.php/psicodebate/article/view/516/311' # url pointing to inline reader. also 2 galleys: pdf and xml
)
galleys <- ojsr::get_galley_url(socPsy_articles, use_conventional_url = TRUE, verbose = TRUE) 
```

Result is in a long-format dataframe (1 input_url may result in several rows, one for each output_url), containing:

1. *input_url* - the url you provided
2. *output_url* - the galleys url scraped
3. *format* - the format of the galley (e.g., pdf, xml)
4. *download_url* - the conventional url to force download of the galley. You may pass these to a download function of your own (e.g., <https://stackoverflow.com/questions/39246739/download-multiple-files-using-download-file-function>).



## get_search_url: Searchs for a criteria in OJS and returns the search result url

`get_search_url()` takes a vector of OJS urls and a string for search criteria to compose the search url. If `check_pagination = TRUE`, it runs the search in OJS to see if pagination is involved, and returns the url for the search result pages. You may then pass these urls to any other `get_*_url()` function. 

Since several parameters and url need to the formed, this function always invokes `ojsr::process_urls()` and works with conventional url (`$conventional_search`).

```{r}
socPsy_journals <- c( # 2 social psychology journals
  'https://revistapsicologia.uchile.cl/index.php/RDP/', # home url
  'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/current' # current issue url
)
search_criteria <- "social representations"
search_results <- ojsr::get_search_url(socPsy_journals, search_criteria = "psicología social", check_pagination = TRUE, verbose = TRUE)
```


Result is in a long-format dataframe (1 input_url may result in several rows, one for each output_url), containing:

1. *input_url* - the url you provided
2. *output_url* - the search page result urls



## get_meta_from_html: Scrap metadata from html of OJS pages

`get_meta_from_html()` takes a vector of OJS urls and scraps the metadata written in the html. Search criteria: \<meta\> tags in the \<head\> section of the html (`method='scrap_meta_in_head'`, default). **Important!** This may not only retrieve bibliographic metadata; any other "meta" property detailed on the html will also be captured (e.g., descriptions for propagation on social network, etc.).

Metadata is usually present in any article-related page. However, since some galley formats force the download of a file, the safest place to search for them is the view of the article (e.g., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/593>). If you provide an url with an article ID (it could be a view of the article, another galley, etc.), and keep `use_conventional_url = TRUE` (default), ojsr will parse the urls given with `process_urls()` to form the conventional url (`$conventional_article`) to scrap metadata.


```{r}
socPsy_articles <- c( # 3 articles on social psychology, specifically social representations theory
  'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/2137', # url pointing at the article page
  'https://dspace.palermo.edu/ojs/index.php/psicodebate/article/view/516/311' # url pointing at a particular galley (xml)
)
metadata <- ojsr::get_meta_from_html(socPsy_articles, use_conventional_url = TRUE, verbose = TRUE) 
```

Result is in a long-format dataframe (1 inputUrl may result in several rows, one for each outputUrl), containing:

1. *input_url* - the url you provided
2. *meta_data_name* - name of the property/metadata (e.g., "DC.Date.created" for the Date of creation) 
3. *meta_data_content* - the actual value of the metatag
4. *meta_data_scheme* - the standard in which the content is annotated
5. *meta_data_xmllang* - the language in which the metadata was entered



## get_meta_from_oai: Retrieve OAI records for OJS articles

**Note:** This function is in a very preliminar stage. If you are interested in working with OAI records, you may want to check Scott Chamberlain's **OAI package for R** <https://CRAN.R-project.org/package=oai>. If you only have the OJS home url, and would like to check all the article's OAI records at one shot, an interesting option is to parse it with `ojsr::process_urls()` and passing the OAI url (`$conventional_oai`) to `oai::list_identifiers()`.

An alternative to webscraping metadata from the html of article pages is to retrieve their OAI-PMH (Open Archives Initiative Protocol for 'Metadata' Harvesting) records <http://www.openarchives.org/OAI/openarchivesprotocol.html>

`get_meta_from_oai()` will try to access (within the OJS) the OAI records for any article for which you provided an url. Since several parameters and url need to the formed, this function always invokes `ojsr::process_urls()`.

```{r}
socPsy_articles <- c( # 2 articles on social psychology, specifically social representations theory
  'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/2137', # url pointing to the article page
  'https://dspace.palermo.edu/ojs/index.php/psicodebate/article/view/516/311' # url pointing a particular galley (xml)
)
metadata_oai <- ojsr::get_meta_from_oai(socPsy_articles, verbose = TRUE)
```

Result is in a long-format dataframe (1 inputUrl may result in several rows, one for each outputUrl), containing:

1. *input_url* - the url you provided
2. *meta_data_name* - name of the property/metadata (e.g., "DC.Date.created" for the Date of creation) 
3. *meta_data_content* - the actual value of the metatag


