---
title: "ojsr-vignette"
author: "Gaston Becerra"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ojsr-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include = FALSE}
library(knitr)
```



# Overview



The aim of this package is to aid retrieve/scraping meta-data and/or accessing galleys (full-text and supplementary files) from OJS url(s).

This package currently provides:

- 1 function (**process_urls**) to parse OJS ulrs, according to OJS routing conventions, to identify what type of page are they pointing at, and to write the expected url for each scrapping task;
- 1 function (**get_metadata_from_page**) to collect meta-data from OJS articles page (via html scraping)
- 1 function (**get_galley_urls**) to retrieve meta-data from OJS article OAI record

It is intended that this package will include:

- 1 function to crawl archive
- 1 function to crawl issue(s)
- 1 function to crawl search results
- some auxiliary functions (to identify OJS version (via generator metatag), to store/download full-text files, etc.)
- 1 dataset of handy codes for scraping


## Important! 

- Most of ojsr functions **rely on OJS conventions and default themes**, and therefore are most likely to fail when used on customized OJS installments (i.e., customized themes, routing improvements via .htaccess), and also on non-compliant OJS configuration and record keeping (i.e., when metadata has not been well-broomed by the Editor/Publisher, or OAI records do not follow standards). 
- Also, please notice that only **common OJS v1 and v2 conventions** are considered (see "OJS v3 and OJS API" below).



## About OJS

(from the OJS documentation <https://pkp.sfu.ca/ojs/>, as of Jan.2020)

Open Journal Systems (OJS) is a journal management and publishing system that has been developed by the Public Knowledge Project through its federally funded efforts to expand and improve access to research.

OJS assists with every stage of the refereed publishing process, from submissions through to online publication and indexing. Through its management systems, its finely grained indexing of research, and the context it provides for research, OJS seeks to improve both the scholarly and public quality of refereed research.

OJS is open source software made freely available to journals worldwide for the purpose of making open access publishing a viable option for more journals, as open access can increase a journalâ€™s readership as well as its contribution to the public good on a global scale (see PKP Publications).



## OJS v3 and OJS API

There is not a simpler, more reliable (less conventional!), way to access meta-data from OJS? 

Yes, there is! Since OJS v3.1+ <https://docs.pkp.sfu.ca/dev/api/ojs/3.1> a Rest API is provided, and we're positive a better R interface should use that API instead of web scraping themes and OAI records.

So, why ojsr? 

Well... According to <https://pkp.sfu.ca/ojs/ojs-usage/ojs-stats/>, as of 2019 (when v3.1+ was launched), OJS was being used by at least 10,000 journals worldwide. OJS is an excellent free publishing solution for institutions that could not publish otherwise. Presumably, most of them do not have the the technical nor financial capabilities to update constantly, so OJS v1 and v2 are expected to be around for quite some time... 



# How to use ojsr?

## process_urls: Parse urls to check what type of OJS page they point at

Let's say you have a bunch of OJS specific article urls you'd like to scrap their meta-data, or a curated list of journals you'd like to crawl completely. However, not all of them may be poiting to the *right* type of OJS page for your purposes (e.g., articles url you collected may be downloading pdf directly, so you won't be able to scrap meta-data, or the issues may be pointing at cover pages that do not include ToCs). 

`process_urls()` allows you to parse a**list of urls against OJS routing conventions** and determine what type of page are they pointing at, which parameters are invoked (e.g., article, issues, galley IDs), and generate the *(assumed to be) right* url for specific purposes, such as scraping meta-data, or scraping the list of issues for the archive of issues page. Most of the times `process_urls()` is invoked before the scraping functions (see the example code for `get_issue_urls_from_archive()`). 

Please keep in mind that `process_urls()` works with **routing conventions** (see <https://docs.pkp.sfu.ca/dev/documentation/en/architecture-routes>). The list of urls you input is not actually browsed.


```{r}
# let's start by loading the libraries
library(ojsr) 
library(tidyverse) # we'll use dplyr and tidy several times in the examples
```

Your urls could look like these:

```{r}
# a mix of different types of OJS pages, including a few illformed
url_sample <- c( 'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/2903',
          'http://fundacionmenteclara.org.ar/revista/index.php/RCA/issue/view/2018-Vol3-2',
          'http://fundacionmenteclara.org.ar/revista/index.php/RCA/article/download/43/54',
          'https://firstmonday.org/ojs/index.php/fm/article/view/9540',
          'http://imed.pub/ojs/index.php/iam/article/view/1650',
          'http://fundacionmenteclara.org.ar/revista/index.php/RCA/oai',
          'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/view/444',
          'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/search/search?query=complejidad'
)

```

We'll parse them, and store the result in a dataframes (`what_type_of_urls`)

```{r}
what_type_of_urls <- ojsr::process_urls(url_sample)
glimpse(what_type_of_urls)
```

The resulting dataframe contains the following:

1. *url* - the url you provided
2. *page* - the page class the url is pointing at (article, issue, oai, search, etc.)
3. *command* - the name of the function within the page (view, download, search, etc.)
4. *expect* - what you could do at this page; usually a combination of command + page or a variant: 
    i) *view article*: shows the abstract page, with references and links to galleys (full-content, supplementary materials) (i.e.,  <https://papiro.unizar.es/ojs/index.php/rc51-jos/article/view/1047>)
    ii) *view galley*: shows an inline reader of a galley (i.e., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/6/2803>)
    iii) *download galley*: forces a galley download (i.e., <https://papiro.unizar.es/ojs/index.php/rc51-jos/article/download/1047/1050>)
    iv) *current issue coverpage*: redirects the current issue coverpage; may or may not include ToC and links to articles (i.e., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/current>)
    v) *view issue coverpage*: shows an issue coverpage; may or may not include ToC and links to articles (i.e., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/view/526>)
    vi) *view issue ToC*: shows the ToC of an issue (with link to articles and galleys) (i.e., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/view/526/showToC>)
    vii) *view issue archive*: shows the list of issues (i.e, <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/issue/archive>)
    viii) *oai*: shows the OAI protocol base URL (i.e., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/oai>)
    ix) *search*: shows search form / result (i.e., <https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/search/search?query=big+data>)
5. *issueId* - if an issue, its ID; otherwise ""
6. *articleId* - if an article, its ID; otherwise ""
7. *galleyId* - if a galley (full-content, supplementary materials, etc.), its ID; otherwise ""
8. *assume_article* - the *(assumed to be) right* url to scrap metadata from an article (if articleID is present, otherwise "")
9. *assume_issue* - the *(assumed to be) right* url to scrap the ToC from an issue (if issueID is present, otherwise "")
10. *assume_oai* - the *(assumed to be) right* url to the OAI records listing
11. *assume_search* - the *(assumed to be) right* url to a search result (you may contact to a query)
12. *assume_archive* - the *(assumed to be) right* url to scrap the list of issues
13. *baseUrl* - base url of the OJS, for you to do your own processing.


## get_issue_urls_from_archive: Retrieve issues urls from the archive of issues

Let's say you want to crawl a few journals in order to list their issues, so you can latter iterate through them and scrap articles' meta-data. We can use `get_issue_urls_from_archive()` for that. 

`get_issue_urls_from_archive()` requires a list OJS urls pointing at the archive of issues of each journal (e.g., <https://papiro.unizar.es/ojs/index.php/rc51-jos/issue/archive>). If you are unsure about your url list, you can first pre-process it with `process_urls()` and use the  *assumed-to-be-right* url instead.

```{r}
# let's start by providing a mix url list of argentinian social psychology journals 
socPsy_urls <- c( 
  'http://sportsem.uv.es/j_sports_and_em/index.php/rips/', # home page of journal, including ToC of current issue
  'https://dspace.palermo.edu/ojs/index.php/psicodebate/issue/archive', # points at the archive of issues
  'https://publicaciones.sociales.uba.ar/index.php/psicologiasocial/article/view/2903' # points at an article 
)

# we'll use process_urls to retrieve the assumed url for archive of issues (what_type_of_urls$assume_archive)
what_type_of_urls <- ojsr::process_urls(socPsy_urls)

# we'll use get_issue_urls_from_archive to retrieve the issues' link from the archives
issues <- get_issue_urls_from_archive(what_type_of_urls$assume_archive )

# result is in a dataframe
glimpse(issues)
```
